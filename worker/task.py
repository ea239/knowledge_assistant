from loguru import logger
from worker.app import celery_app
from api.db import SessionLocal
from api.models.article import Article

# âœ… å¼•å…¥åˆšæ‰å†™å¥½çš„ä¸šåŠ¡é€»è¾‘
from services.crawler import parse_article_from_url
from services.embed_service import generate_embedding_for_article
from api.services.search_indexer import upsert_article_to_meili

@celery_app.task(name="worker.tasks.parse_url")
def parse_url(url: str):
    logger.info(f"ðŸ“¥ [Task] Parsing URL: {url}")
    
    # 1. çˆ¬å–
    data = parse_article_from_url(url)
    if not data:
        return "Parse Failed"
    
    db = SessionLocal()
    try:
        # 2. æŸ¥é‡
        existing = db.query(Article).filter(Article.url == data["url"]).first()
        if existing:
            # ðŸ’¡ è¡¥æ•‘æŽªæ–½ï¼šå¦‚æžœ URL å·²å­˜åœ¨ï¼Œé¡ºæ‰‹åŒæ­¥ä¸€ä¸‹ Meiliï¼Œé˜²æ­¢æ¼ç½‘ä¹‹é±¼
            upsert_article_to_meili(existing)
            logger.info(f"â­ï¸ URL exists. Synced to Meili: {existing.title}")
            return f"Skipped: {existing.id}"

        # 3. å…¥åº“
        new_article = Article(
            url=data["url"],
            title=data["title"],
            content_text=data["content_text"],
            source_platform=data["source_platform"],
            author=data.get("author")
        )
        db.add(new_article)
        db.commit()
        db.refresh(new_article)
        logger.info(f"ðŸ’¾ Saved article to DB: {new_article.title}")

        # 4. ðŸ”¥ åŒæ­¥åˆ° Meilisearch (æ–°å¢žè¿™ä¸€æ­¥)
        try:
            upsert_article_to_meili(new_article)
        except Exception as e:
            logger.error(f"âš ï¸ Failed to sync to Meili: {e}")

        # 5. è§¦å‘åŽç»­ä»»åŠ¡
        embed_article.delay(str(new_article.id))
        summarize_article.delay(str(new_article.id))
        
        return f"Parsed & Saved: {new_article.id}"

    except Exception as e:
        logger.error(f"âŒ DB Error: {e}")
        db.rollback()
    finally:
        db.close()

@celery_app.task(name="worker.tasks.ocr_image")
def ocr_image(s3_key: str):
    logger.info(f"ðŸ–¼ï¸ [TODO] OCR å›¾ç‰‡: {s3_key}")
    # è¿™é‡Œå°†æ¥å†™: ä¸‹è½½å›¾ç‰‡ -> OCR -> å…¥åº“
    # è¿™ä¸€æ­¥å¯¹åº” Timeline Step 6


@celery_app.task(name="worker.tasks.embed_article", bind=True, max_retries=3)
def embed_article(self, article_id: str):
    """
    Step 8: è¯­ä¹‰æ£€ç´¢çš„æ ¸å¿ƒä»»åŠ¡
    è°ƒç”¨ services/embed_service ç”Ÿæˆå‘é‡å¹¶å­˜åº“
    """
    logger.info(f"ðŸš€ [Task] Starting embedding for {article_id}")
    try:
        # è°ƒç”¨æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
        result = generate_embedding_for_article(article_id)
        
        if result:
            logger.success(f"âœ… [Task] Embedding generated successfully for {article_id}")
        else:
            logger.warning(f"âš ï¸ [Task] Embedding finished but returned None (maybe empty text?)")
            
    except Exception as e:
        logger.error(f"âŒ [Task] Embedding failed for {article_id}: {e}")
        # å¤±è´¥è‡ªåŠ¨é‡è¯•ï¼š10ç§’åŽé‡è¯•
        raise self.retry(exc=e, countdown=10)

@celery_app.task(name="worker.tasks.summarize_article")
def summarize_article(article_id: str):
    # æ²¡ API Key ä¹Ÿä¸æ€•ï¼Œå…ˆæ”¾ç€ã€‚ç­‰åšäº† Step 9 å†æ¥å¡«è¿™é‡Œã€‚
    logger.info(f"ðŸ¤– [TODO] Skip Summary (No LLM API yet): {article_id}")
    # è¿™é‡Œå°†æ¥å†™: è°ƒç”¨ DeepSeek/OpenAI -> ç”Ÿæˆæ‘˜è¦ -> æ›´æ–° DB
